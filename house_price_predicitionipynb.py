# -*- coding: utf-8 -*-
"""House_Price_Predicitionipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11f0l5DOFra_ZQSujJDohDhqq4Kxu3Mvm
"""

import numpy as np
import pandas as pd

df1 = pd.read_csv('/content/drive/MyDrive/test.csv')
df2 = pd.read_csv('/content/drive/MyDrive/train.csv')
df3 = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')

df1.head()

df2.head()

df3.head()

df1.tail()

df2.tail()

df3.tail()

df1.info()

df2.info()

df3.info()

y = df2['SalePrice']
X = df2.drop('SalePrice',axis=1)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)

x = X_train.isnull().sum()>0
null_cols = x[x].index
X_train[null_cols].isna().sum()

null_dic = X_train[null_cols].isna().sum().to_dict()
cols_todrop = []
for k , v in null_dic.items():
    if v > 684:
        cols_todrop.append(k)
cols_todrop

X_train.drop(cols_todrop,axis=1,inplace=True)
X_test.drop(cols_todrop,axis=1,inplace=True)

cols_tofill = null_cols.drop(cols_todrop)

num_cols = X_train.select_dtypes(include=np.number).columns.tolist()
cat_cols = X_train.select_dtypes(exclude=np.number).columns.tolist()
X_train_num = X_train[num_cols]
X_train_cat = X_train[cat_cols]

import matplotlib.pyplot as plt
import seaborn as sns
corr_matrix = X_train_num.corr()
sns.heatmap(corr_matrix)

corr_threshold = 0.8
num_col_todrop = []
for i in range(len(num_cols)):
    for j in range(i+1,len(num_cols)):
        if corr_matrix.iloc[i,j]>corr_threshold:
            num_col_todrop.append(corr_matrix.index[j])

num_col_todrop

Num_col = [col for col in num_cols if col not in num_col_todrop]
Cat_col = [col for col in cat_cols]

from sklearn.pipeline import Pipeline,make_pipeline
from sklearn.impute import KNNImputer,SimpleImputer
from sklearn.preprocessing import MinMaxScaler,OneHotEncoder,OrdinalEncoder
from sklearn.compose import ColumnTransformer

more_cat_col = []
less_cat_col = []
for col in cat_cols:
    if(len(X_train[col].unique())>10):
        more_cat_col.append(col)
    else:
        less_cat_col.append(col)
more_cat_col

num_prcessor = make_pipeline(KNNImputer(),MinMaxScaler())
more_cat_precessor = make_pipeline(SimpleImputer(strategy='constant',fill_value='Missint'),OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=40))
less_cat_precessor = make_pipeline(SimpleImputer(strategy='constant',fill_value='Missing'),OneHotEncoder(handle_unknown='ignore'))

trf = ColumnTransformer([
    ('numerical',num_prcessor,Num_col),
    ('more_categorical',more_cat_precessor,more_cat_col),
    ('less_categorical',less_cat_precessor,less_cat_col)
],remainder='passthrough')

from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor
def prediction(model):

    pipline = Pipeline([
        ('transformer',trf),
        ('model',model)
    ])
    pipline.fit(X_train,y_train)
    y_pred = pipline.predict(X_test)
    print(f"{model}")
    print(f"r2_score is {r2_score(y_test, y_pred)}")
    print(f"mean_absolute_error is {mean_absolute_error(y_test, y_pred)}")
    print(f"Root mean squared error is {np.sqrt(mean_squared_error(y_test, y_pred))}")

rf = RandomForestRegressor()
prediction(rf)

best_model = GradientBoostingRegressor()
prediction(best_model)

from xgboost import XGBRegressor
XGb = XGBRegressor()
prediction(XGb)

Id = df1['Id']
Id

test_processed = trf.transform(df1)
predictions = best_model.predict(test_processed)

predictions_df = pd.DataFrame({
    'Id': Id,
    'SalePrice': predictions
})
predictions_df.to_csv('submission2.csv', index=False)